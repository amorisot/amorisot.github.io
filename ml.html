<!doctype html>
<html>
  <head>
    <link rel="icon" type="image/png" href="favicon.png"/>
    <link rel="stylesheet" href="static/style.css">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>adrien</title>
  </head>
  <body>
    <div id="menu">
      <li><a href="about">ğŸ¡</a></li>
      <li><a href="art">ğŸ‘¨â€ğŸ¨</a></li>
      <li><a href="ml">ğŸ¤–</a></li>
      <li><a href="books">ğŸ“š</a></li>
    </div>
    <div id="left">
      &nbsp;
    </div>
    <div id="content">
      <h1>ML</h1>
      <p>I like ML and think it's cool and important.</p>
      <p>This list is a compilation of papers I found particularly helpful or thought-provoking.</p>
      <hr>
      <div>
        <span> 
          <h4>It's possible to measure the intrinsic dimension of the loss landscape.</h4>
          <p>https://arxiv.org/abs/1804.08838</p>
        </span>
        <hr>
        <span>
          <h4>The embeddings obtained from BERT are much less anisotropic (i.e. self-similar) than those obtained from GPT.</h4>
          <p>https://arxiv.org/abs/1909.00512</p>
        </span>
        <hr>
        <span>
          <h4>Big convolutional neural networks are not calibrated, but big transformers are.</h4>
          <p>https://arxiv.org/abs/1706.04599 and https://arxiv.org/abs/2003.07892</p>
        </span>
        <hr>
        <span>
          <h4>Imposing fairness constraints on ML systems can backfire in the long run. This paper scooped my Master's thesis!</h4>
          <p>https://arxiv.org/abs/1803.04383</p>
        </span>
        <hr>
        <span>
          <h4>Predictive policing is a bad idea.</h4>
          <p>https://arxiv.org/abs/1706.09847, which is based on <a href="https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/j.1740-9713.2016.00960.x">this</a> fantastic paper</p>
        </span>
        <hr>
      </div>
    </div>
  </body>
</html>