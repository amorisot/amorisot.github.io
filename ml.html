<!doctype html>
<html>
  <head>
    <link rel="icon" type="image/png" href="favicon.png"/>
    <link rel="stylesheet" href="static/style.css">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML - adrien</title>
  </head>
  <body>
    <div id="menu">
      <li><a href="about">üè°</a></li>
      <li><a href="art">üë®‚Äçüé®</a></li>
      <li><a href="ml">ü§ñ</a></li>
      <li><a href="books">üìö</a></li>
    </div>
    <div id="left">
      &nbsp;
    </div>
    <div id="content">
      <h1>ML</h1>
      <p>I enjoy ML research and think it's fun and important.</p>
      <p>I wrote a paper by myself, and contributed to a couple at Cohere.</p>
      <div>
        <hr>
        <span> 
          <h4>Neural nets should not spend the same amount of compute per example. Some points are demonstrably easier than others to classify.</h4>
          <p><a href="https://arxiv.org/abs/2007.13512">https://arxiv.org/abs/2007.13512</a></p>
        </span>
        <hr>
        <span>
          <h4>You can use a trained language model to select good datapoints to train future models on.</h4>
          <p><a href="https://arxiv.org/abs/2107.02565">https://arxiv.org/abs/2107.02565</a></p>
        </span>
        <hr>
        <span>
          <h4>You can use the likelihood of a large language model to identify toxic content in a dataset.</h4>
          <p><a href="https://arxiv.org/abs/2108.07790">https://arxiv.org/abs/2108.07790</a></p>
        </span>
        <hr>
      </div>
      <p>This list is a compilation of papers I found particularly helpful or thought-provoking.</p>
      <div>
        <hr>
        <span> 
          <h4>It's possible to measure the intrinsic dimension of the loss landscape.</h4>
          <p><a href="https://arxiv.org/abs/1804.08838">https://arxiv.org/abs/1804.08838</a></p>
        </span>
        <hr>
        <span>
          <h4>The embeddings obtained from BERT are much less anisotropic (i.e. self-similar) than those obtained from GPT.</h4>
          <p><a href="https://arxiv.org/abs/1909.00512">https://arxiv.org/abs/1909.00512</a></p>
        </span>
        <hr>
        <span>
          <h4>Big convolutional neural networks are not calibrated, but big transformers are.</h4>
          <p><a href="https://arxiv.org/abs/1706.04599">https://arxiv.org/abs/1706.04599</a> and <a href="https://arxiv.org/abs/2003.07892">https://arxiv.org/abs/2003.07892</a></p>
        </span>
        <hr>
        <span>
          <h4>Imposing fairness constraints on ML systems can backfire in the long run. This paper scooped my Master's thesis!</h4>
          <p><a href="https://arxiv.org/abs/1803.04383">https://arxiv.org/abs/1803.04383</a></p>
        </span>
        <hr>
        <span>
          <h4>Predictive policing is a bad idea.</h4>
          <p><a href="https://arxiv.org/abs/1706.09847">https://arxiv.org/abs/1706.09847</a>, which is based on <a href="https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/j.1740-9713.2016.00960.x">this</a> fantastic paper</p>
        </span>
        <hr>
      </div>
    </div>
  </body>
</html>
